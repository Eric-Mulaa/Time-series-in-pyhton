{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pmdarima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d sumanthvrao/daily-climate-time-series-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have more than one csv files in the zip file and I need to load the two of them\n",
    "zip_file_path = 'daily-climate-time-series-data.zip'\n",
    "\n",
    "# Step 1: Read both CSV files directly from the ZIP archive\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    with zip_ref.open('DailyDelhiClimateTrain.csv') as train_file:\n",
    "        df_train = pd.read_csv(train_file)\n",
    "\n",
    "    with zip_ref.open('DailyDelhiClimateTest.csv') as test_file:\n",
    "        df_test = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let have a lok at the first few rows of our datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let now see the shapes of these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the data types of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to convert the 'date' column to a datetime object and make it to be the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['date'] = pd.to_datetime(df_train['date'], format = '%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.set_index('date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency of the this dataset is not set, I will proceed and set it to 'D' for days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.asfreq('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will repeat the same process with the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['date'] = pd.to_datetime(df_test['date'], format = '%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.set_index('date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.asfreq('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('correlation coefficients among the four aspects')\n",
    "print('meantemp and humidity correlation: \\t\\t' + str(df_train['meantemp'].corr(df_train['humidity'])))\n",
    "print('meantemp and wind_speed correlation: \\t\\t' + str(df_train['meantemp'].corr(df_train['wind_speed'])))\n",
    "print('humidity and wind_speed correlation: \\t\\t' + str(df_train['humidity'].corr(df_train['wind_speed'])))\n",
    "print('meantemp and meanpressure correlation: \\t\\t' + str(df_train['meantemp'].corr(df_train['meanpressure'])))\n",
    "print('humidity and meanpressure correlation: \\t\\t' + str(df_train['humidity'].corr(df_train['meanpressure'])))\n",
    "print('wind_speed and meanpressure correlation: \\t' + str(df_train['wind_speed'].corr(df_train['meanpressure'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanpressure is weakly correlated with the pther three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df_train.corr(method='pearson'), figsize=(6,4))\n",
    "plt.title('Correlation Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this reason I will not consider meanpressure in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_train['meanpressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot.area(figsize = (8, 5))\n",
    "plt.xlabel('Time')\n",
    "plt.title('All Changes')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_train.columns\n",
    "for col in col_names:\n",
    "     plt.figure(figsize=(12, 5))\n",
    "     # Defining subplots in one row and two columns\n",
    "     # In index one of the subplot, we will have histogram\n",
    "     plt.subplot(1, 3, 1)\n",
    "     sns.histplot(data=df_train, x=col, kde=True, color = '#911116', line_kws={'color': '#911156'})\n",
    "     plt.xlabel(col)\n",
    "     plt.ylabel('Frequency')\n",
    "     plt.title(f'Distribution of {col}')\n",
    "     # The second index subplot will have boxplots\n",
    "     plt.subplot(1, 3, 2)\n",
    "     sns.boxplot(data=df_train, y=col)\n",
    "     plt.ylabel(col)\n",
    "     plt.title(f'Box Plot of {col}')\n",
    "     # The third plot will display the observations\n",
    "     plt.subplot(1,3,3)\n",
    "     sns.lineplot(data=df_train, x=df_train.index, y=col)\n",
    "     plt.xlabel('Time')\n",
    "     plt.ylabel(col)\n",
    "     plt.title(f'Observations of {col}')\n",
    "     plt.xticks(rotation=90)\n",
    "     # To make sure that no overlapping \n",
    "     plt.tight_layout()\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets observe the monthly distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = df_train.groupby(df_train.index.month).mean()\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.lineplot(data=monthly)\n",
    "plt.xlabel('Month')\n",
    "plt.title('Monthly Observations ')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seasonality here is quite clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now decompose this dataset into trend, seasonality and noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_names:\n",
    "    decomposition = seasonal_decompose(df_train[col], period=365)\n",
    "    decomposition.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a strong seasonality in Meantemp, Humidity, Windspeed.\n",
    "\n",
    "Also, Meantemp has an upward trend over the year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now observe the Argumented Dicke-Fuller test and see the p-values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_names:\n",
    "    print('The p-value for ' + col + ' is: ' + str(adfuller(df_train[col])[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meantemp is non-stationary, remember that the Argumented Dickey-Fuller test tests only the trend. We can not see the seasonality trend here but we know it is present in all the three aspects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see the the ACF and PACF plots \n",
    "\n",
    "Remember the frequency of our train data is set to daily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_names:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 3))\n",
    "    \n",
    "    # The first index subplot will have ACF\n",
    "    plot_acf(df_train[col], lags=60, zero=False, ax=ax1)\n",
    "    ax1.set_title(f'ACF of {col}')\n",
    "    \n",
    "    # The second index subplot will have PACF\n",
    "    plot_pacf(df_train[col], lags=60, zero=False, ax=ax2)\n",
    "    ax2.set_title(f'PACF of {col}')\n",
    "    \n",
    "    # To make sure that no overlapping \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see non-stationarity in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting a model, we need to know the seasonal and non-seasonal differencing orders. We will start by detrending the non-seasonal trend for meantemp and check the adfuller p-value after the first differencing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meantemp_diff = df_train['meantemp'].diff().diff(365)\n",
    "meantemp_diff = meantemp_diff.dropna()\n",
    "decomp = seasonal_decompose(meantemp_diff, period =365)\n",
    "decomp.plot()\n",
    "plt.title('First seasonal and non-seasonal difference')\n",
    "plt.show()\n",
    "print('The p-value for  meantemp_diff is: ' + str(adfuller(meantemp_diff)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp.seasonal.plot()\n",
    "plt.title('seasonal plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meantemp is stationary after one differencing of both seasonal and non-seasonal trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the seasonal and non-seasonal trends are now detrended, all by the first difference order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 3))\n",
    "    \n",
    "plot_acf(meantemp_diff, lags=60, zero=False, ax=ax1)\n",
    "ax1.set_title('ACF for Stationary meantemp')\n",
    "    \n",
    "plot_pacf(meantemp_diff, lags=60, zero=False, ax=ax2)\n",
    "ax2.set_title('PACF for Stationary meantemp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now fit a SARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(df_train['meantemp'], order=(4, 1, 3), seasonal_order=(4, 1, 3, 365))\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target variable and exogenous variables\n",
    "# y = df_train['meantemp']\n",
    "# X = df_train[['humidity', 'wind_speed']]  # Pass exogenous variables as a DataFrame\n",
    "\n",
    "# Fit the ARIMA model with exogenous variables\n",
    "# results = pm.auto_arima(y, exogenous=X, seasonal=True, m=365, max_d=1, max_D=1, trend='ct',\n",
    "                        # stepwise=False, suppress_warnings=True, error_action='ignore',\n",
    "                        # max_p=6, max_q=6, max_Q=4, max_P=4, n_jobs=-1, information_criterion='aic')\n",
    "                        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
